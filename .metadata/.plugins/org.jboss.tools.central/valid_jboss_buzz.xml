<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">Keycloak tutorial for beginners</title><link rel="alternate" href="http://www.mastertheboss.com/keycloak/introduction-to-keycloak/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/keycloak/introduction-to-keycloak/</id><updated>2023-02-02T16:15:12Z</updated><content type="html">Keycloak is an Identity and Access Management Server for Modern Applications and Services. In this Keycloak tutorial we will learn how to set up Keycloak and configure it to authenticate/authorize Enterprise applications. Keycloak update (2023) Keycloak is available in two distributions: Legacy distribution (which uses WildFly as runtime engine). Quarkus distribution (which uses Quarkus as ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to use a Datasource in Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-use-a-datasource-in-quarkus/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/quarkus/how-to-use-a-datasource-in-quarkus/</id><updated>2023-02-02T10:13:18Z</updated><content type="html">Agroal is a connection pool implementation that can be used with Quarkus to manage database connections. In this tutorial, we will go over how to use the DataSource in a Quarkus application. First, you’ll need to add the Agroal extension to your Quarkus application. You can do this by adding the following dependency to your ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How we added support for the C++23 assume feature in GCC</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/02/02/support-c23-assume-feature-gcc" /><author><name>Andrew MacLeod</name></author><id>add91dac-43e0-4e20-a731-1c64457dff13</id><updated>2023-02-02T07:00:00Z</updated><published>2023-02-02T07:00:00Z</published><summary type="html">&lt;p&gt;For the past few years, I have been working on Project Ranger, a new infrastructure in GCC that determines value ranges of variables in &lt;a href="https://developers.redhat.com/topics/c"&gt;C and C++&lt;/a&gt; programs. This article discusses how Ranger supports the new &lt;code&gt;assume&lt;/code&gt; feature of the C++23 standard, which helps programmers optimize programs.&lt;/p&gt; &lt;p&gt;Ranger is a generic system that performs basic algebraic evaluations using the known ranges of some variables to determine the possible ranges for other variables. Ranger supports several compiler optimizations. I have written two previous articles about Ranger, so please refer to them for background. &lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/10/11/a-upside-down-approach-to-gcc-optimizations#"&gt;An upside-down approach to GCC optimizations&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger#"&gt;Value range propagation in GCC with Project Ranger&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How Ranger improves optimization&lt;/h2&gt; &lt;p&gt;The following example illustrates how Ranger can help GCC remove unnecessary C and C++ code. Assume that all values are signed 8-bit integers and that no overflows can take place.&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;x = y * 2 c = x &gt; 20 if (c) { block 1 } else { block 2 }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Ranger works backward through the expressions, substituting known values into the results and evaluating the inputs. If the &lt;code&gt;if&lt;/code&gt; statement returns a true value (represented in C as 1), we know the following in block 1:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;c = [1,1] // c has a min of 1 and a max of 1. [1, 1] = x &gt; 20 // x &gt; 20, so x = [21, 127] [21, 127] = y * 2 // y = [11, 63]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Likewise, on the false side of the branch, we know the following in block 2:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;c = [0,0] [0, 0] = x &gt; 20 // x &lt;= 20, so x = [-128, 20] [-128, 20] = y * 2 // y = [-64, 10]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Ranger is currently being used by close to a dozen optimization passes to assist with various code transformations.&lt;/p&gt; &lt;h2&gt;An introduction to assume expressions&lt;/h2&gt; &lt;p&gt;As we neared the close of GCC 13 development, I was approached by another developer who was adding basic internal support for the new C++23 &lt;code&gt;assume&lt;/code&gt; keyword. He asked whether Ranger could be used for analysis so that &lt;code&gt;assume&lt;/code&gt; could actually be useful to the compiler.&lt;/p&gt; &lt;p&gt;I had never heard of the &lt;code&gt;assume&lt;/code&gt; keyword before this. It is a mechanism by which the C++ programmer can indicate that an arbitrarily complex expression always evaluates to true.&lt;/p&gt; &lt;p&gt;The other developer handled the feature by turning each &lt;code&gt;assume&lt;/code&gt; expression into an outlined function—a call to a small function that evaluates the expression. My task was to figure out what information we could determine about the parameters of the function based on the assumption that the function always returns a true value.&lt;/p&gt; &lt;p&gt;An example of C++ code we could analyze follows. The three input values (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, and &lt;code&gt;z&lt;/code&gt;) are unsigned.&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;int myfunc (unsigned x, unsigned y, unsigned z) { [[assume (x == 2 &amp;&amp; y &lt; 3 &amp;&amp; z &lt; 20)]]; unsigned q = x + y + z; if (q &gt; 23) call (); return 1; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If we do the job correctly, the compiler figures that &lt;code&gt;q&lt;/code&gt; can never be greater than 23, eliminates the &lt;code&gt;if&lt;/code&gt; expression, and no longer makes the function call.&lt;/p&gt; &lt;h2&gt;Handling the assume expression in Ranger&lt;/h2&gt; &lt;p&gt;As I mentioned, the way GCC implements &lt;code&gt;assume&lt;/code&gt; is to outline a function that handles the assume expression as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;int assume_func (unsigned x, unsigned y, unsigned z) { if (x == 2 &amp;&amp; y &lt; 3 &amp;&amp; z &lt; 20) return 1; return 0; } int my_func (unsigned x, unsigned y, unsigned z) { assume_func (x, y, z); unsigned q = x + y + z; if (q &gt; 23) call (); return 1; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;GCC turns the &lt;code&gt;assume_func&lt;/code&gt; function into a sequence as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt; tmp_3 = x == 2; tmp_5 = y &lt;= 2; tmp_9 = z &lt;= 19; tmp_1 = tmp_5 &amp; tmp_9; tmp_10 = tmp_1 &amp; tmp_3; return tmp_10;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I don't believe that anyone could create a language construct that is more appropriate for demonstrating the power of our new range engine. All that GCC needs is to tap into Ranger and ask what the ranges of &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; are if tmp_&lt;code&gt;10&lt;/code&gt; has a range of &lt;code&gt;[1, 1]&lt;/code&gt;. These would be the values we can "assume" x, y, and z have in my_func(). In a couple of days, I added the necessary tweaks, tested the feature, and checked in the changes required for support.&lt;/p&gt; &lt;p&gt;Working from the bottom to top and starting by substituting 1 for _10, we can  work our way back through the statements and determine the definitions of each expression must also be 1, resulting in expressions for x, y, and z that evaluate as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt; 1 = x == 2; 1 = y &lt;= 2; 1 = z &lt;= 19; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the result to be 1 (TRUE), we can determine the following range for &lt;code&gt;x&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;x → unsigned int [2, 2]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;we can also determine the following range for &lt;code&gt;y&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;y → unsigned int [0, 2]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And finally, we can determine the following range for &lt;code&gt;z&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;z → unsigned int [0, 19]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;These values of &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, and &lt;code&gt;z&lt;/code&gt; are communicated back to the main program effective at the point of the &lt;code&gt;assume&lt;/code&gt; function call. GCC sees myfunc() as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;assume_func (x, y, z); tmp_1 = x + y; q = tmp_1 + z; if (q &gt; 23) call (); return 1; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now GCC's existing value range optimizations are able to determine that the maximum value  tmp_1 can have is 2 + 2 or 4. The maximum value &lt;code&gt;q&lt;/code&gt; can have is 4 &lt;code&gt;+19&lt;/code&gt; which is 23. This allows GCC to determine the branch can never be taken, and it can remove both the if and the call, reducing the entire function to the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;return 1;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;The __builtin_unreachable extension: An C++23 alternative&lt;/h2&gt; &lt;p&gt;What if you don't use C++23? You can access some of the behavior of &lt;code&gt;assume&lt;/code&gt; using the GCC &lt;code&gt;__builtin_unreachable()&lt;/code&gt; extension. This function declares that the condition leading to the call can never be true (the opposite of what &lt;code&gt;assume&lt;/code&gt; says). You could therefore write the preceding program in C like so:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;if (!(x == 2 &amp;&amp; y &lt; 3 &amp;&amp; z &lt; 20)) __builtin_unreachable (); unsigned q = x + y + z; if (q &gt; 23) call (); return 1;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The true power (or perhaps craziness?) of C++23's &lt;code&gt;assume&lt;/code&gt; functionality is that it can be arbitrarily complicated and needs to ignore side effects. This means you can write something very complex (taken from our test suite) as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;int baz (int x) { [[assume (({ int z = ++x; static int w; ++w; if (z == 51) return -1; if (z == 53) goto lab1; if (z == 64) throw 1; z == 43; }))]]; lab1: return x; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;GCC will see through all the complicated bits and ignore the side effects, such as the increment of &lt;code&gt;x&lt;/code&gt;, the &lt;code&gt;goto&lt;/code&gt;, and the &lt;code&gt;throw&lt;/code&gt;. GCC recognizes from this &lt;code&gt;assume&lt;/code&gt; expression that &lt;code&gt;z==43&lt;/code&gt; and &lt;code&gt;z=++x&lt;/code&gt;. The whole snippet is therefore optimized to the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;return 42;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;We provide support for the assume feature&lt;/h2&gt; &lt;p&gt;Although GCC 13 does not have complete support for &lt;code&gt;assume&lt;/code&gt;, we do provide a functional implementation for early C++23 adopters. Give it a try. If you find an expression we can't figure out, open a bug report, and we'll fix it.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/02/02/support-c23-assume-feature-gcc" title="How we added support for the C++23 assume feature in GCC"&gt;How we added support for the C++23 assume feature in GCC&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew MacLeod</dc:creator><dc:date>2023-02-02T07:00:00Z</dc:date></entry><entry><title>3 improvements to the OpenShift 4.12 developer experience</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/02/01/3-improvements-openshift-412" /><author><name>Serena Chechile Nichols</name></author><id>fd2cbeab-7c65-4e12-8443-ebfca4fb7757</id><updated>2023-02-01T14:30:00Z</updated><published>2023-02-01T14:30:00Z</published><summary type="html">&lt;p&gt;Red Hat OpenShift Container Platform 4.12 provides several enhancements based on customer requests and usability improvements to the &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift &lt;/a&gt;console.&lt;/p&gt; &lt;p&gt;The improvements include the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The &lt;strong&gt;Helm&lt;/strong&gt; page now has a dedicated &lt;strong&gt;Repositories&lt;/strong&gt; tab allowing users to manage Helm chart repositories.&lt;/li&gt; &lt;li&gt;When using &lt;strong&gt;OpenShift Serverless&lt;/strong&gt;, workloads created by &lt;strong&gt;Import from Git&lt;/strong&gt; and &lt;strong&gt;Deploy image&lt;/strong&gt; default to &lt;a href="https://developers.redhat.com/topics/serverless-architecture/"&gt;serverless&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;When using &lt;strong&gt;OpenShift Pipelines:&lt;/strong&gt; &lt;ul&gt;&lt;li&gt;Users now have quick access to the parameter values used during a Pipeline Run in the Parameters tab of the PipelineRun details page.&lt;/li&gt; &lt;li&gt;Users can now choose to either Cancel or Stop a running PipelineRun, providing more granular control of the running tasks of the PipelineRun.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Cluster Administrators now have a form-based experience to customize areas of the OpenShift console from &lt;strong&gt;Cluster Settings&lt;/strong&gt;. Although developers cannot use this feature, it provides the ability for admins to provide an improved developer experience. Be on the lookout for an in-depth article about console customization coming soon.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This article will dive into what’s new for developers.&lt;/p&gt; &lt;h2&gt;3 improvements to OpenShift 4.12&lt;/h2&gt; &lt;p&gt;Let’s go into more detail about the improvements in three key areas.&lt;/p&gt; &lt;h3&gt;&lt;span&gt;1. User preferences updates&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;The &lt;strong&gt;Applications&lt;/strong&gt; tab of &lt;strong&gt;User Preferences&lt;/strong&gt; provides default settings that are used in the import from Git and deploy image flows (Figure 1). In addition to security defaults, developers can now set the default workload type in the &lt;strong&gt;Resource type&lt;/strong&gt; section.  When using &lt;strong&gt;OpenShift Serverless&lt;/strong&gt;, this default is set to serverless. Otherwise, it is set to deployment.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience_fig1.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience_fig1.jpg?itok=O6poSt_X" width="600" height="357" alt="Screenshot of the applications tab of user preferences page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The applications tab of the user preferences page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Now let’s look at how this affects the &lt;strong&gt;Import from Git&lt;/strong&gt; and &lt;strong&gt;Deploy Image&lt;/strong&gt; flows. Previously, resource type section was prominent in those user flows. We learned from users that resource type was not something that is typically changed. So once their default was set properly, they didn’t update it frequently. Because of this, we have added the ability to set the default in &lt;strong&gt;User Preferences&lt;/strong&gt; and also moved the &lt;strong&gt;Resource type&lt;/strong&gt; section of our &lt;strong&gt;Import from Git&lt;/strong&gt; and &lt;strong&gt;Deploy Image&lt;/strong&gt; forms to the &lt;strong&gt;Advanced options&lt;/strong&gt; section (see Figure 2).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig2.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig2.jpg?itok=AdTt9kqI" width="600" height="293" alt="Screenshot of the previous and new advanced options page with the Resource type section." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The Resource type section moved to the Advanced option section.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;2. Improved display of limits and quotas issues&lt;/h3&gt; &lt;p&gt;To improve awareness of project limits and quota issues, developers will see a warning label on the top of the &lt;strong&gt;Add&lt;/strong&gt; and &lt;strong&gt;Topology&lt;/strong&gt; page when any project limits and quotas are detected. Figure 3 shows an example of the label on the &lt;strong&gt;Topology&lt;/strong&gt; page, which indicates the number of quotas that have been reached. Developers can click the label to get additional data to detect the issue.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig3.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig3.jpg?itok=AT8xaJDt" width="600" height="267" alt="A screenshot of the quota issues label on the topology page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The quota issues label on the Topology page indicating the number of quotas reached.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When multiple quotas have been reached, the user is brought to the list page of Resource Quotas (see Figure 4). Otherwise, users will be redirected to the details page of that specific resource quota.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig4.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig4.jpg?itok=RE3qinFD" width="600" height="242" alt="The Resource Quotas page showing resources reached quotas." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: The Resource Quotas page showing resources reached quotas.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Taking this a step further, additional visual indicators are shown in &lt;strong&gt;Topology&lt;/strong&gt; on resources that have surpassed limits or quotas. Figure 5 illustrates an example of how developers can identify these issues at different zoom levels. Developers can gain additional information about the detected problem by clicking on the node and viewing the information in the side panel. An in-context link is provided, allowing the developer to navigate to the specific flow to fix the issue. In this case, it would allow them to edit the resource limits of the deployment.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig5.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig5.jpg?itok=hxyiGU9W" width="600" height="266" alt="A screenshot of issues at different zoom levels." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: You can view issues at different zoom levels.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This is one of my favorite features of the release. Currently, when limits and quotas are reached, developers have to go to the &lt;strong&gt;Project Details&lt;/strong&gt; page to get information. We now inform the user as soon as the issue is detected. Additionally, we provide them with one-click access to either get more information or resolve the issue (Figure 6).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-exp-fig6-img7.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-exp-fig6-img7.jpg?itok=c9cCdx2D" width="600" height="314" alt="One-click access to resolve the issue." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: One-click access to learn how to resolve the issue.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;3. End-to-end KafkaSink support&lt;/h3&gt; &lt;p&gt;Receive and store CloudEvents from Source/Subscription/Trigger on a Kafka topic without writing custom code as follows:&lt;/p&gt; &lt;p&gt;When the CR for knativeKafka is created with sink enabled, developers can create a KafkaSink from the Event Sink Catalog. Users will have a form-based experience to create a KafkaSink (Figure 7). Once created, a KafkaSink can be added as subscriber, trigger, and event-source sink targets. Developers can accomplish by using drag-and-drop or the action buttons.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig6.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig6.jpg?itok=ra4ih8cj" width="600" height="341" alt="The form-based creation flow for KafkaSink." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 7: The form-based creation flow for KafkaSink.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;How to get started with OpenShift 4.12&lt;/h2&gt; &lt;p&gt;Ready to try these new features for yourself? Get started with OpenShift 4.12 today on the &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-developer-sandbox-trial"&gt;Developer Sandbox&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Check out the following resources to learn more about the new OpenShift 4.12 release:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BwIKMBhj3mQ"&gt;What's New in OpenShift 4.12 [Developer Edition]&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/c/RedHatDevelopers"&gt;Red Hat Developer YouTube channel&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/try-it"&gt;Try Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;If you have questions, feel free to comment below or reach out to us. Community feedback helps us to continually improve the OpenShift developer experience. Tweet me &lt;a href="http://twitter.com/serenamarie125"&gt;@serenamarie125&lt;/a&gt; or join the &lt;a href="https://groups.google.com/g/openshift-dev-users"&gt;OpenShift Developer Experience Google group&lt;/a&gt; to share your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/02/01/3-improvements-openshift-412" title="3 improvements to the OpenShift 4.12 developer experience"&gt;3 improvements to the OpenShift 4.12 developer experience&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Serena Chechile Nichols</dc:creator><dc:date>2023-02-01T14:30:00Z</dc:date></entry><entry><title type="html">New Feature: Dashbuilder editor with IntelliSense capabilities</title><link rel="alternate" href="https://blog.kie.org/2023/02/new-feature-dashbuilder-editor-with-intellisense-capabilities.html" /><author><name>Ajay Jaganathan</name></author><id>https://blog.kie.org/2023/02/new-feature-dashbuilder-editor-with-intellisense-capabilities.html</id><updated>2023-02-01T14:02:58Z</updated><content type="html">We are pleased to announce that the dashbuilder editor now ships with auto-complete capabilities! This enhances the user experience by providing suggestions and helps to reduce the errors made while authoring the dashbuilder specification.  Let’s go through the new features in the below section: AUTO-COMPLETE SUGGESTIONS: While typing out a particular word or pressing ctrl+space, the editor provides the list of possible values for that particular context. The user can select the appropriate one from the list of possible values and automatically complete it. If any required field is missing, it also prompts the user with error messages. Below is a short video of the auto-complete capability in action. Autocomplete while authoring CREATING A SAMPLE DASHBUILDER SPECIFICATION(CODE LENS): When starting with an empty file, the editor provides a code lens to auto-fill the file with a sample dashbuilder specification. This gives the user some boilerplate code to start authoring the specification. Below is a sample video of the code lens feature in action. Codelens in action CONCLUSION These features are implemented to reduce the complexity of authoring a dashboard and the errors made while doing it. These features are available in all of our extensions! Stay tuned to learn more about the new features planned for . The post appeared first on .</content><dc:creator>Ajay Jaganathan</dc:creator></entry><entry><title type="html">Quarkus 2.16.1.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-16-1-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-16-1-final-released/</id><updated>2023-02-01T00:00:00Z</updated><content type="html">We released Quarkus 2.16.1.Final, our first maintenance release for the 2.16 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 2.16. For people using Micrometer, the format used to export metrics has changed in 2.16 (for the Prometheus format),...</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title>4 steps to run an application under OpenShift Service Mesh</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/01/30/run-app-under-openshift-service-mesh" /><author><name>Bob Reselman</name></author><id>d1ce9ade-4833-4161-84b6-5364934680d7</id><updated>2023-01-30T07:00:00Z</updated><published>2023-01-30T07:00:00Z</published><summary type="html">&lt;p&gt;This article is a follow-up to &lt;a href="https://developers.redhat.com/articles/2023/01/11/developers-guide-using-openshift-kubernetes"&gt;A developer's guide to using OpenShift with Kubernetes&lt;/a&gt; which describes the nature and use of Red Hat OpenShift Service Mesh in general. This article applies these concepts using a hands-on demonstration application to run OpenShift Service Mesh.&lt;/p&gt; &lt;p&gt;A &lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;service mesh&lt;/a&gt; provides many benefits when running a &lt;a href="https://developers.redhat.com/articles/2022/01/19/monolith-microservices-how-applications-evolve"&gt;microservice oriented application (MOA)&lt;/a&gt; under &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;OpenShift&lt;/a&gt;/&lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. You can think of a service mesh as a one-ring-to-rule-them-all approach to MOA management. With a service mesh, you don’t need to fiddle with the details of the security well-being and operational particulars of &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; with an MOA on a pod-by-pod, service-by-service basis. Rather, the service mesh takes care of it all.&lt;/p&gt; &lt;p&gt;But sadly, there is no magic. A service mesh comes with its own set of components, and they need to be configured according to the needs of the application. Thus, you need to know a thing or two about service mesh configuration details, particularly when working with a service mesh under OpenShift. OpenShift combines configuration implementation using its graphical web console and the &lt;code&gt;oc&lt;/code&gt; command line tool. As a result, things can be a bit tricky. This article provides a demonstration of setting up the OpenShift Service Mesh, as shown in the following video.&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;An overview&lt;/h2&gt; &lt;p&gt;There will be a good deal of explanation that goes with each of the following hands-on activities.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;You will learn the workflow for configuring and running a demonstration application under OpenShift Service Mesh.&lt;/li&gt; &lt;li&gt;We will describe the demonstration application.&lt;/li&gt; &lt;li&gt;You will learn how the service mesh controls the demonstration application from a conceptual point of view.&lt;/li&gt; &lt;li&gt;Follow the steps to get the demonstration application up and running under an OpenShift Service Mesh.&lt;/li&gt; &lt;li&gt;Configure service mesh destination rules that control access to the constituent components used by the application.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;In order to get the full benefit from this article, you will need to fulfill the following prerequisites:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Understand the basics of how an OpenShift cluster works.&lt;/li&gt; &lt;li&gt;Know how Kubernetes resources such as &lt;a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"&gt;Namespaces&lt;/a&gt;, &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"&gt;Deployments&lt;/a&gt;, &lt;a href="https://kubernetes.io/docs/concepts/workloads/pods/"&gt;Pods&lt;/a&gt;, and &lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/"&gt;Services&lt;/a&gt; are used within an OpenShift cluster.&lt;/li&gt; &lt;li&gt;Understand how a service uses&lt;a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/"&gt; labels as selectors&lt;/a&gt; to identify the pods with the logic that the service will represent.&lt;/li&gt; &lt;li&gt;You should be familiar with OpenShift/Kubernetes configuration files written in YAML format.&lt;/li&gt; &lt;li&gt;Access to a fully-operational version of OpenShift to get hands-on experience working with the service mesh described in this article.&lt;/li&gt; &lt;li&gt;Know how to create projects within OpenShift.&lt;/li&gt; &lt;li&gt;You need administrator permissions to install the OpenShift Operators required to implement a fully functional Service Mesh.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The Kubernetes and service mesh configuration files used to create and control the demonstration application in your OpenShift cluster are available for &lt;a href="https://github.com/redhat-developer-demos/simple-service-mesh-demo"&gt;download&lt;/a&gt;. Also provided in those files is a setup shell script that will install the demonstration application automatically. However, before you run that setup script, the following prerequisite conditions must be met:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The OpenShift Service Mesh must be installed.&lt;/li&gt; &lt;li&gt;The demonstration application’s namespace must be created.&lt;/li&gt; &lt;li&gt;The demonstration application’s namespace must be bound to the service mesh under the default &lt;code&gt;ServiceMeshMemberRoll&lt;/code&gt; resource.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The article will provide the details for satisfying these three conditions.&lt;/p&gt; &lt;p&gt;The Service Mesh configuration files are linked throughout this article. It would be helpful to open those links in a separate browser window for easy reference.&lt;/p&gt; &lt;h2&gt;A description of the demonstration application&lt;/h2&gt; &lt;p&gt;The demonstration application is an aggregate of three microservices: orders, payments, and recommendations. The main point of entry is the orders microservice represented as a RESTful API.&lt;/p&gt; &lt;p&gt;The orders microservice uses other microservices. These microservices are payments to receive and process payments and recommendations which the orders service uses to provide a recommendation message after a purchase has been made. Also, the recommendations microservice gets data from constituent Kubernetes deployments. These deployments are recommendations-music and recommendations-food. Recommendations-music provides recommendations about music. Recommendations-food provides recommendations about food (see Figure 1).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig1.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig1.jpg?itok=_h8DUM0s" width="600" height="268" alt="The microservice architecture for the demonstration application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The microservice architecture for the demonstration application.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;By default, the recommendations microservice gets a recommendation from recommendations-music and recommendations-food in a round-robin manner, alternating accordingly. However, we’re going to use the capabilities of the service mesh to apply a rule that overrides round-robin routing between the constituent recommendation services and makes a recommendation come solely from recommendations-food.&lt;/p&gt; &lt;p&gt;Then, we will delete that rule and apply a rule that makes a recommendation come only from recommendations-music. We won't have to configure any of the underlying deployments, pods, and services that are part of the cluster. Rather, all behavior changes will be accomplished by configuring the OpenShift Service Mesh.&lt;/p&gt; &lt;h2&gt;How the service mesh works&lt;/h2&gt; &lt;p&gt;As mentioned, you can think of the OpenShift Service Mesh as a one-ring-to-rule-them-all approach to controlling behavior in and around an application running within an OpenShift cluster. Once you make an application known to the service mesh, the service mesh is in charge. The service mesh controls access to the application, routing within the application, and how the application’s components interact with each other.&lt;/p&gt; &lt;p&gt;Three service mesh resources facilitate access, routing, and internal interaction: &lt;/p&gt; &lt;ol&gt;&lt;li&gt;Gateway&lt;/li&gt; &lt;li&gt;Virtual service&lt;/li&gt; &lt;li&gt;Destination rules&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;The gateway is the entry point&lt;/h3&gt; &lt;p&gt;Once a Service Mesh is in force, the gateway is the entry point for all traffic according to the port number assigned to the gateway. A Service Mesh can have many gateways. A gateway defines a port number and domain name to access the cluster.&lt;/p&gt; &lt;p&gt;You will learn more details about gateways in a later section. The important thing to understand now is that all external traffic going into the service mesh must pass thru this gate.&lt;/p&gt; &lt;h3&gt;The purpose of a virtual service&lt;/h3&gt; &lt;p&gt;You can think of a virtual service as an overlay service that the service mesh imposes on an existing OpenShift/Kubernetes service. The virtual service adds its own routing definition that gets processed according to the request URL passed to the gateway. The job of the gateway URL is to get a request into the service mesh. The purpose of the virtual service is to determine how to route the request once it’s received.&lt;/p&gt; &lt;p&gt;As shown in Figure 2, a user passes a request to &lt;code&gt;http://istio-gateway-mydomain.io/&lt;/code&gt; into the Service Mesh. The gateway knows it can allow this request to enter the service mesh. The virtual service, &lt;code&gt;virtual-service-orders&lt;/code&gt;, is configured to recognize all requests with a root URL (/) and pass them onto the underlying orders service running in the OpenShift cluster.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig2.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig2.jpg?itok=f8S8XTJx" width="600" height="168" alt="Applying the service mesh gateway and virtual service to the demonstration application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Applying the service mesh gateway and virtual service to the demonstration application.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As you’ll see in the following sections, a service mesh can have many virtual services, with each service dedicated to processing some aspect of an incoming request.&lt;/p&gt; &lt;h3&gt;How a virtual service uses destination rules&lt;/h3&gt; &lt;p&gt;A destination rule is used by a virtual service to determine what the service must do upon receiving a request. A destination rule can describe how to configure the pods assigned to a service according to a particular label definition. Within the scope of this article, you’ll use a destination rule that knows how to work with the labels, &lt;code&gt;version: food&lt;/code&gt; and &lt;code&gt;version: music&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Figure 3 shows a virtual service, &lt;strong&gt;virtual-service-food&lt;/strong&gt;, that controls the behavior of the underlying OpenShift/Kubernetes service named &lt;strong&gt;recommendations&lt;/strong&gt;. &lt;strong&gt;Virtual-service-food&lt;/strong&gt; uses a destination rule &lt;a href="https://istio.io/latest/docs/reference/config/networking/destination-rule/#Subset"&gt;subset&lt;/a&gt;, &lt;strong&gt;recommendation-food&lt;/strong&gt;, as shown at callout (1).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig3.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig3.jpg?itok=1yH5GRtF" width="600" height="257" alt="Applying a destination rule to a virtual service." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Applying a destination rule to a virtual service.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;That subset rule dictates that &lt;code&gt;virtual-service-food &lt;/code&gt;should only select pods that have the label &lt;code&gt;version: food&lt;/code&gt;. When the rule is applied, the underlying recommendations service in the OpenShift cluster will bind to pods that have the &lt;code&gt;version: food&lt;/code&gt; pair, as shown in callout (2) of Figure 3, along with the recommendation's original selector label, &lt;code&gt;app: recommendation&lt;/code&gt;, which is not shown.&lt;/p&gt; &lt;p&gt;Admittedly, Figure 3 is a bit complex, and understanding and applying a destination rule can be a bit tricky. You need to have a firm understanding about how Kubernetes labels work as &lt;a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/"&gt;service selectors&lt;/a&gt; to bind pods to a service. It can take some time to absorb it all.&lt;/p&gt; &lt;p&gt;We’ll discuss using destination rules later in this article. The important thing to remember now is that a destination rule is applied to a virtual service by the virtual service’s configuration. Once the destination rule is applied, the virtual service will make it so the underlying Kubernetes service binds to pods according to the given destination rule in force.&lt;/p&gt; &lt;p&gt;Now that we have covered the essentials, let’s move on to the hands-on portion of this article.&lt;/p&gt; &lt;h2&gt;4 steps to run an application under OpenShift Service Mesh&lt;/h2&gt; &lt;p&gt;The sections that follow describe the steps to take to install the OpenShift Service Mesh Operator and the demonstration application, along with applying the various service mesh components required to run it all under the service mesh. Figure 4 illustrates an overview of the workflow.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig4.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig4.jpg?itok=098Dd__a" width="600" height="330" alt="The steps required to install and run the demonstration application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: The steps required to install and run the demonstration application under an OpenShift Service Mesh.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;h3&gt;Step 1: Install the service mesh operator&lt;/h3&gt; &lt;p&gt;Service Mesh technology is not part of a standard installation of OpenShift. Rather, the components that are part of OpenShift Service Mesh need to be added to OpenShift. These components are represented by a set of Kubernetes Operators which are added to the OpenShift cluster by personnel that have Administrator permissions. &lt;/p&gt; &lt;p&gt;Figure 5 shows the operators that are part of a service mesh installation under OpenShift. These components are &lt;a href="https://catalog.redhat.com/software/containers/openshift-service-mesh/istio-rhel8-operator/5d6ed9285a13461f5f020c15"&gt;RedHat OpenShift Service Mesh Operator&lt;/a&gt;, &lt;a href="https://catalog.redhat.com/software/operators/detail/5f32f067651c4c0bcecf1bfe"&gt;OpenShift Elasticsearch Operator&lt;/a&gt;, &lt;a href="https://catalog.redhat.com/software/operators/detail/5ec54a5c78e79e6a879fa271"&gt;RedHat OpenShift distributed tracing platform Operator&lt;/a&gt; and the &lt;a href="https://kiali.io/"&gt;Kiali Operator&lt;/a&gt;.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig5.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig5.jpg?itok=fs3UCGpJ" width="600" height="260" alt="The operators that make up a service mesh installation under OpenShift." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: The operators that make up a service mesh installation under OpenShift.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;All of the operators shown in Figure 5 are available for installation from the OpenShift Operator Hub.&lt;/p&gt; &lt;p&gt;Table 1 describes the purpose of each Operator.&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="900"&gt;&lt;caption&gt;Table 1: The operators that make up a service mesh installation under OpenShift&lt;/caption&gt; &lt;thead&gt;&lt;tr&gt;&lt;th scope="col"&gt; &lt;p&gt;&lt;strong&gt;Operator&lt;/strong&gt;&lt;/p&gt; &lt;/th&gt; &lt;th scope="col"&gt;Description&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href="https://catalog.redhat.com/software/containers/openshift-service-mesh/istio-rhel8-operator/5d6ed9285a13461f5f020c15"&gt;&lt;u&gt;RedHat OpenShift Service Mesh Operator&lt;/u&gt;&lt;/a&gt;&lt;/td&gt; &lt;td&gt;The operator represents the control and data planes of the core service mesh. The operator is based on the Istio service mesh.&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href="https://catalog.redhat.com/software/operators/detail/5f32f067651c4c0bcecf1bfe"&gt;&lt;u&gt;OpenShift Elasticsearch Operator&lt;/u&gt;&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Used to store tracing and cluster logging information within the service mesh.&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href="https://catalog.redhat.com/software/operators/detail/5ec54a5c78e79e6a879fa271"&gt;&lt;u&gt;RedHat OpenShift distributed tracing platform Operator&lt;/u&gt;&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Based on the Jaeger open source project, provides distributed tracing capabilities within the service mesh.&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href="https://kiali.io/"&gt;&lt;u&gt;Kiali Operator&lt;/u&gt;&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Provides the capability to graphically visualize a variety of the service mesh’s activities, such as circuit breaking and request rates.&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;ul&gt;&lt;/ul&gt;&lt;h3&gt;Step 2: Create a namespace for the service mesh&lt;/h3&gt; &lt;p&gt;Once the operators are installed and running, the following steps need to be executed:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Step 2a: Create the namespace for the application to OpenShift Cluster.&lt;/li&gt; &lt;li&gt;Step 2b: Configure the service mesh to “know” about this namespace.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;In order for an OpenShift Service Mesh to control an application, that application needs to run in a dedicated OpenShift namespace. In this case, we’re going to create a namespace and call it, &lt;strong&gt;service-mesh-demo&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;One way to create a dedicated namespace in OpenShift is to create an OpenShift project. Then, OpenShift will do the work of creating the namespace as part of the project creation process.&lt;/p&gt; &lt;p&gt;Other ways are to create a namespace declaratively by using a YAML configuration file or imperatively by executing a command using the &lt;code&gt;oc&lt;/code&gt; CLI tool for OpenShift at a terminal window. Both the imperative and declarative methods require that you are logged into an OpenShift cluster using the &lt;code&gt;oc&lt;/code&gt; CLI tool as a credentialed user.&lt;/p&gt; &lt;h4&gt;Step 2a:&lt;strong&gt; &lt;/strong&gt; Create the ​​​​namespace in the OpenShift cluster&lt;/h4&gt; &lt;p&gt;Run the following &lt;code&gt;oc&lt;/code&gt; command in a terminal window:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc create namespace service-mesh-demo&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Alternatively, you can use a configuration YAML file to create the namespace using the command: &lt;code&gt;apply -f .yaml as follows:&lt;/code&gt;&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: v1 kind: Namespace metadata: name: service-mesh-demo labels: name: service-mesh-demo &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;How you create the namespace is up to you. The important thing is that the namespace must be created before you add it to the Service Mesh.&lt;/p&gt; &lt;h4&gt;Step 2b: Add the application’s namespace to the service mesh&lt;/h4&gt; &lt;p&gt;Once the namespace is created, add it to the service mesh’s ServiceMeshMemberRoll resource using the configuration file as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: maistra.io/v1 kind: ServiceMeshMemberRoll metadata: finalizers: - maistra.io/istio-operator generation: 12 name: default namespace: istio-system spec: members: - service-mesh-demo&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The easiest way to add the namespace to the service mesh is to execute the following &lt;code&gt;oc&lt;/code&gt; command in a terminal window against the YAML file that describes the &lt;code&gt;ServiceMeshMemberRoll&lt;/code&gt; configuration. (Note: As always, you must be logged into your instance of OpenShift by way of &lt;code&gt;oc login&lt;/code&gt;.)&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f  https://raw.githubusercontent.com/redhat-developer-demos/simple-service-mesh-demo/main/service-mesh/service-member-roll.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After the namespace is added to the &lt;code&gt;ServiceMeshMemberRoll&lt;/code&gt; resource, it will appear within the OpenShift web console administrator view under &lt;strong&gt;Installed Operators&lt;/strong&gt; in the web console. Click the Istio Service Mesh Roll link as shown in Figure 6 at callout (5).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig6.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig6.jpg?itok=MVWvwNeV" width="600" height="280" alt="The ServiceMeshMemberRoll detail page within the OpenShift web console." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: Access the ServiceMeshMemberRoll detail page within the OpenShift web console.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Then, once the Service Mesh Roll Detail page appears, click the YAML link as shown in Figure 7 at callout (2). You’ll see the namespace service-mesh-demo added to the members attribute as shown at callout (3).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig7.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig7.jpg?itok=q8XKr121" width="600" height="356" alt="Shows the addition of the demonstration namespace to the ServiceMeshMemberRoll resource." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 7: The YAML link on the OpenShift web console indicates the addition of the demonstration namespace to the ServiceMeshMemberRoll resource.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The important thing to understand about adding the demonstration application’s &lt;code&gt;service-mesh-demo&lt;/code&gt; namespace to the service mesh via the &lt;code&gt;ServiceMeshMemberRoll&lt;/code&gt; resource is that adding the namespace is how the service mesh “knows” about the demonstration application. This is important because once the Service Mesh “knows” about the &lt;code&gt;service-mesh-demo &lt;/code&gt;namespace, the service mesh will automatically inject proxy sidecar containers into all pods created within the demonstration application’s namespace. These proxy sidecar containers allow the service mesh to take control of the demonstration application.&lt;/p&gt; &lt;p&gt;Now that the Service Mesh knows about the demonstration application’s namespace, it’s time to add the demonstration application’s Kubernetes resources to OpenShift and the Service Mesh.&lt;/p&gt; &lt;h3&gt;Step 3: Install Kubernetes resources for the demo app&lt;/h3&gt; &lt;p&gt;You can install the demonstration application’s Kubernetes resources into the OpenShift cluster by running a setup shell script included with the resource configuration files stored on a GitHub repository dedicated to this article. The next steps will explain how to download and install the demonstration application’s Kubernetes resources into OpenShift.&lt;/p&gt; &lt;h4&gt;Step 3a: Clone the code&lt;/h4&gt; &lt;p&gt;Run the following command in a terminal window to download the setup script and Kubernetes resource files onto your local computer.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;git clone https://github.com/redhat-developer-demos/simple-service-mesh-demo&lt;/code&gt;&lt;/pre&gt; &lt;h4&gt;Step 3b:&lt;strong&gt; &lt;/strong&gt;Install the pods and services&lt;/h4&gt; &lt;ul&gt;&lt;li&gt;Once the source code is downloaded from GitHub, navigate into the &lt;code&gt;./k8s&lt;/code&gt; folder of the source code’s working directory by running the following command from the terminal window of your local machine: &lt;/li&gt; &lt;/ul&gt;&lt;p class="Indent2"&gt;&lt;code&gt;cd openshift-service-mesh-examples/k8s/&lt;/code&gt;&lt;/p&gt; &lt;ul&gt;&lt;li&gt;When you are in the &lt;code&gt;./k8s&lt;/code&gt; folder, run the following command in a terminal window to install the Kubernetes resources associated with the demonstration application:&lt;/li&gt; &lt;/ul&gt;&lt;p class="Indent2"&gt;&lt;code&gt;sh ./app-setup.sh&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The setup script installs the pods and services that make up the demonstration application. If everything installs as expected, the circular deployment graphics will be displayed in the &lt;strong&gt;Developer Topology&lt;/strong&gt; view of the OpenShift web console, as shown in Figure 8.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/servicemesh-fig8.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/servicemesh-fig8.jpg?itok=UC-Dmi66" width="600" height="246" alt="Shows the demo app’s deployments in the Topology view." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 8: The demonstration application’s deployments appear in the Topology view upon successful installation.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once the Kubernetes resources are installed, you’re ready to make the demonstration application operational under the OpenShift Service Mesh.&lt;/p&gt; &lt;h3&gt;Step 4: Build the service mesh&lt;/h3&gt; &lt;p&gt;As mentioned previously, once you've installed the demo application’s Kubernetes resources in the OpenShift cluster, the next set of steps is to configure the OpenShift Service Mesh to support the application. The steps that make up the process are as follows:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Step 4a:&lt;/strong&gt; Install the Service Mesh Gateway.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Step 4b:&lt;/strong&gt; Install the Virtual Service for the Orders Service.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Step 4c:&lt;/strong&gt; Install the Destination Rules.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Step 4d:&lt;/strong&gt; Add a Virtual Service to enable filtering the Recommendations according to a version: food.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Step 4e:&lt;/strong&gt; Delete the existing Virtual Service.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Step 4f:&lt;/strong&gt; Add a new Virtual Service to enable filtering the Recommendations according to a version: music.&lt;/li&gt; &lt;/ul&gt;&lt;h4&gt;Step 4a: Install the service mesh gateway&lt;/h4&gt; &lt;p&gt;As you learned earlier, the gateway is the “gate” by which requests enter the service mesh. The configuration file for the gateway is in the &lt;code&gt;./service-mesh &lt;/code&gt;folder of the source code you downloaded from GitHub. The following shows the contents of the Gateway configuration:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: service-mesh-demo-gateway namespace: service-mesh-demo spec: selector: istio: ingressgateway # use istio default controller servers: - port: number: 80 name: http protocol: HTTP hosts: - "*" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The gateway configuration file allows access to any request sent to port 80 of the OpenShift Cluster. The gateway is applicable to all hosts, as indicated by the last two lines of the configuration file.&lt;/p&gt; &lt;p&gt;Execute the following command to install the gateway into the OpenShift Service Mesh:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/redhat-developer-demos/simple-service-mesh-demo/main/service-mesh/gateway.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The gateway allows requests into the service mesh, but once a request is in the service mesh, it must be routed to a relevant service. This is where a virtual service comes into play.&lt;/p&gt; &lt;h4&gt;Step 4b: Install the virtual service&lt;/h4&gt; &lt;p&gt;The following configuration file for the virtual service supports the underlying Kubernetes order service:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: virtual-service-orders namespace: service-mesh-demo spec: hosts: - "*" gateways: - service-mesh-demo-gateway ############################################### http: # This Virtual Service listens for requests - match: # coming in on this Gateway, service-mesh-demo-gateway - uri: ############################################### exact: / ############################################### route: # Any root request, for example, a request coming from: - destination: # http://istio-ingressgateway-istio-system.apps.mydomain.eastus.aroapp.io/ host: orders # will be forwarded to the Kubernetes service named orders at port 8080 port: ############################################### number: 8080&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The configuration file for the Virtual Service routes a request to the orders service.&lt;/p&gt; &lt;p&gt;The way a virtual service works in an OpenShift Service Mesh is that its configuration file declares a definition that identifies a particular URI pattern to support. Then, that request will be forwarded to an underlying OpenShift/Kubernetes service. In the case of this virtual service called &lt;code&gt;virtual-service-orders&lt;/code&gt;, the URI pattern is the root (/). As the comments explain, the virtual service will look at requests coming in through the &lt;code&gt;service-mesh-demo-gateway&lt;/code&gt;, the previously installed gateway. Then, it will forward all root requests to the destination host &lt;code&gt;orders&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In service mesh configuration parlance, the term &lt;strong&gt;host&lt;/strong&gt; corresponds to the underlying Kubernetes service called &lt;strong&gt;orders&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Execute the following command to install the &lt;code&gt;virtual-service-orders&lt;/code&gt; into the OpenShift Service Mesh:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/redhat-developer-demos/simple-service-mesh-demo/main/service-mesh/virtual-service-orders.yaml&lt;/code&gt;&lt;/pre&gt; &lt;h4&gt;Review so far&lt;/h4&gt; &lt;p&gt;Let’s review briefly. So far, you have configured the service mesh to allow GET and POST requests to the demonstration application. The demonstration application will return behavior defined by the &lt;code&gt;virtual-service-orders&lt;/code&gt; virtual service. The host is assigned the value &lt;code&gt;orders&lt;/code&gt; designated in the virtual service configuration. That setting corresponds to the underlying Kubernetes &lt;code&gt;orders&lt;/code&gt; service.&lt;/p&gt; &lt;p&gt;In turn, the underlying &lt;code&gt;orders&lt;/code&gt; service uses the Kubernetes &lt;code&gt;payments&lt;/code&gt; service as well as the Kubernetes &lt;code&gt;recommendations&lt;/code&gt; service. Then the Kubernetes &lt;code&gt;recommendations&lt;/code&gt; service gets recommendation data from the &lt;code&gt;recommendation-food&lt;/code&gt; and &lt;code&gt;recommendation-music&lt;/code&gt; pods in a round-robin manner.&lt;/p&gt; &lt;p&gt;In order to confirm all is working as expected, get the URL published by the service mesh to gain access to the demonstration application.&lt;/p&gt; &lt;p&gt;Execute the following command to get the URL to your instance of the OpenShift Service mesh:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc -n istio-system get route istio-ingressgateway -o jsonpath='{.spec.host}'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You'll get a response that is somewhat similar but not exactly the same as the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;http://istio-ingressgateway-istio-system.apps.mydomain.eastus.app.io&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can copy the URL returned by the command and paste it into a program such as &lt;a href="https://www.postman.com/"&gt;Postman&lt;/a&gt; to execute a GET request to the demonstration application running in the OpenShift cluster. As mentioned previously, you’ll be getting recommendation data from the &lt;code&gt;recommendation-food&lt;/code&gt; and &lt;code&gt;recommendation-music&lt;/code&gt; pods.&lt;/p&gt; &lt;p&gt;However, we can restrict the recommendation information returned by the application to a particular recommendation pod by using a destination rule and an additional virtual service.&lt;/p&gt; &lt;h4&gt;Step 4c: Install the destination rules&lt;/h4&gt; &lt;p&gt;As mentioned previously, a &lt;a href="https://istio.io/latest/docs/reference/config/networking/destination-rule/"&gt;destination rule&lt;/a&gt; is an instruction (a.k.a. policy) that tells a virtual service what to do with a request. A destination rule can be configured in a variety of ways. In the case of the demonstration application, we’ve created a destination rule that declares two subsets. A subset is a named configuration setting that defines particular labels applied to a designated host as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: service-mesh-demo-destination-rule namespace: service-mesh-demo spec: host: recommendations subsets: ############################################## - name: recommendation-food # Have the K8S service recommendations labels: # use pods that have, version: food defined version: food # as labels in the pods metadata attribute. - name: recommendation-music ############################################## labels: # Have the K8S recommendations service use version: music # pods with the label version: music ############################################## &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This destination rule has two subsets that describe the type of recommendation used by the demonstration application.&lt;/p&gt; &lt;p&gt;One subset named &lt;code&gt;recommendation-food&lt;/code&gt; tells the Kubernetes &lt;code&gt;recommendations&lt;/code&gt; service to only include pods that have the label &lt;code&gt;version: food&lt;/code&gt; as part of its selector definition. Remember, Kubernetes service binds to pods according to the labels that the service and pods have in common, as defined in the &lt;code&gt;spec.selector&lt;/code&gt; section of the service.&lt;/p&gt; &lt;p&gt;Another subset named &lt;code&gt;recommendation-music&lt;/code&gt; will make the Kubernetes service only include recommendation data from the recommendation-music pod.&lt;/p&gt; &lt;p&gt;Execute the following command to install the &lt;code&gt;service-mesh-demo-destination-rule&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/redhat-developer-demos/simple-service-mesh-demo/main/service-mesh/destination-rule.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, we’ll create a virtual service that uses only the subset named &lt;code&gt;recommendation-food&lt;/code&gt;. That subset tells the virtual service to add the label, &lt;code&gt;version: food&lt;/code&gt;, (the service’s selector) in addition to any selector labels that are already explicitly defined in the service’s configuration file. You can view the recommendations service’s configuration file &lt;a href="https://github.com/redhat-developer-demos/simple-service-mesh-demo/blob/main/k8s/recommendations.yaml"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h4&gt;Step 4d: Implement a virtual service to enable recommendations filtering&lt;/h4&gt; &lt;p&gt;Using a destination rule requires implementing a virtual service that declares a route to a host supported by a destination rule. Remember, in virtual service terminology, the &lt;strong&gt;host&lt;/strong&gt; indicates an underlying Kubernetes service.&lt;/p&gt; &lt;p&gt;The following declares an attribute host with the value &lt;code&gt;recommendation&lt;/code&gt; at the &lt;code&gt;spec.http.route.destination&lt;/code&gt; attribute. Also, &lt;code&gt;spec.http.route.destination&lt;/code&gt; has a sub-attribute named &lt;code&gt;subset&lt;/code&gt; that has the value, &lt;code&gt;recommendation-food&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: virtual-service-food namespace: service-mesh-demo spec: hosts: - recommendations http: - route: - destination: ############################################## host: recommendations # The K8S recommendations service, in addition subset: recommendation-food # to using the labels declared in its Port: # spec.selector attribute, will bind to pods number: 8080 # that also have labels defined in the weight: 100 # recommendation-food subset of the Destination # Rule. ##############################################&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The virtual service uses recommendations that have been filtered to use only pods with labels defined in the recommendation-food subset of the destination rule.&lt;/p&gt; &lt;p&gt;The meaning of the settings can be expressed as the following: “Whenever a call to the Kubernetes service recommendations is made, go find a Destination Rule that has a subset named &lt;code&gt;recommendation-food&lt;/code&gt; defined. Then get the label assigned to that subset and retrieve the pods that have that label defined in its metadata attribute.”&lt;/p&gt; &lt;p&gt;This means that when the &lt;code&gt;orders&lt;/code&gt; service calls the &lt;code&gt;recommendations&lt;/code&gt; service to get a recommendation, the virtual service named &lt;code&gt;virtual-service-food&lt;/code&gt; takes over. The virtual service &lt;code&gt;virtual-service-food&lt;/code&gt; , in turn, goes into the service mesh and looks for a destination rule subset named &lt;code&gt;recommendation-food&lt;/code&gt;. As you might recall, the subset &lt;code&gt;recommendation-food&lt;/code&gt; is defined in the destination rule named &lt;code&gt;service-mesh-demo-destination-rule&lt;/code&gt;. The &lt;code&gt;recommendation-food&lt;/code&gt; subset declares a label &lt;code&gt;version: food&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Thus, the service mesh will only use pods that have the labels &lt;code&gt;app: recommendations&lt;/code&gt; and &lt;code&gt;version: food&lt;/code&gt;. (Don’t forget&lt;strong&gt; &lt;/strong&gt;the label &lt;code&gt;app: recommendations&lt;/code&gt; is the selector declared in the original K8S &lt;code&gt;recommendations&lt;/code&gt; service. The label &lt;code&gt;app: recommendations&lt;/code&gt; is declared in the metadata of the K8S deployment named &lt;code&gt;recommendation-food&lt;/code&gt; along the label &lt;code&gt;version: food&lt;/code&gt;. Hence the binding of the Kubernetes &lt;code&gt;recommendations&lt;/code&gt; service to the &lt;code&gt;recommendation-food&lt;/code&gt; pod. You can view the &lt;code&gt;recommendations-food&lt;/code&gt; deployment on &lt;a href="https://github.com/redhat-developer-demos/simple-service-mesh-demo/blob/main/k8s/recommendations.yaml"&gt;my GitHub page&lt;/a&gt;.)&lt;/p&gt; &lt;p&gt;Thus, the logic that is in play when the K8S &lt;code&gt;recommendations&lt;/code&gt; service is called is that a recommendation such as &lt;em&gt;"&lt;/em&gt;Buy some more excellent pastry&lt;em&gt;"&lt;/em&gt; will be emitted by the &lt;code&gt;recommendation-food&lt;/code&gt; pod and thus returned by the K8S &lt;code&gt;recommendations&lt;/code&gt; service. Logically, the virtual service, &lt;code&gt;virtual-service-food&lt;/code&gt;, has a filter in force that only returns recommendations from the K8S pod &lt;code&gt;recommendation-food.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Execute the following command to install the virtual service named virtual-service-food into the OpenShift Service Mesh:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/redhat-developer-demos/simple-service-mesh-demo/main/service-mesh/virtual-service-food.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To see the destination rule in action execute the following &lt;code&gt;curl&lt;/code&gt; command in your terminal window. (Note: Substitute the URL published by your instance of the OpenShift Service Mesh in place of the string &lt;SERVICE_MESH_URL&gt;.) &lt;/p&gt; &lt;p&gt;POSTing &lt;code&gt;order&lt;/code&gt; data to the demonstration application:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;curl --location --request POST 'http:&lt;SERVICE_MESH_URL&gt;/' \ --header 'Content-Type: application/json' \ --data-raw '{ "customer": { "id": 3, "firstName": "Barney", "lastName": "Kelly", "email": "Barney.Kelly@gmail.com" }, "product": { "id": 2, "category": "Food", "description": "Blue Olives", "price": 39.99 }, "creditCard": { "number": "6767-8196-4877-7940-326", "expirationDate": "2023-09-08T01:14:59.686Z", "cvv": "851", "cardHolder": { "id": 3, "firstName": "Barney", "lastName": "Kelly", "email": "Barney.Kelly@gmail.com" } }, "purchaseDate": 1669844628249 }'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You’ll get output similar to the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;{ "status": 200, "order": { "payment": { "customer": { "id": 3, "firstName": "Barney", "lastName": "Kelly", "email": "Barney.Kelly@gmail.com" }, "product": { "id": 2, "category": "Food", "description": "Blue Olives", "price": 39.99 }, "creditCard": { "number": "6767-8196-4877-7940-326", "expirationDate": "2023-09-08T01:14:59.686Z", "cvv": "851", "cardHolder": { "id": 3, "firstName": "Barney", "lastName": "Kelly", "email": "Barney.Kelly@gmail.com" }, "authorizationCode": "93d945c8-af67-43cf-9de0-82f2780ed31f" }, "purchaseDate": 1669844628249, "id": "b132a95b-6238-45dd-b809-995e8a1d5619" }, "recommendation": { "category": "food", "recommendation": "Buy some more excellent Pastry" }, "id": "fceadf7f-6f04-469d-9922-9a74cfc8d57a" } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is the output from POSTing an order to the demo application when the destination rule subset &lt;code&gt;recommendation-food&lt;/code&gt; is in force. Notice that only a food recommendation is returned as part of the response to the request to the demo application.&lt;/p&gt; &lt;h4&gt;Applying a different destination rule using a new virtual service&lt;/h4&gt; &lt;p&gt;Should you want to use only recommendations from the pods in the&lt;code&gt;recommendations-music&lt;/code&gt; deployment you’ll need to delete the Virtual Service named &lt;code&gt;virtual-service-food&lt;/code&gt; from the service mesh. Then, you'll apply the Virtual Service named &lt;code&gt;virtual-service-music&lt;/code&gt;.&lt;/p&gt; &lt;h4&gt;Step 4e: Delete the existing virtual service&lt;/h4&gt; &lt;p&gt;Execute the following command in the terminal window to delete the virtual service called, &lt;code&gt;virtual-service-food&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc delete virtualservice virtual-service-food -n service-mesh-demo&lt;/code&gt;&lt;/pre&gt; &lt;h4&gt;Step 4f: Add a virtual service to enable recommendations filtering according to a version: music&lt;/h4&gt; &lt;p&gt;Now it's time to create the a virtual service that will use recommendations coming from the K8S deployment &lt;code&gt;recommendations-music&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The following configuration for the virtual service named &lt;strong&gt;virtual-service-music&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: virtual-service-music namespace: service-mesh-demo spec: hosts: - recommendations http: - route: - destination: ############################################## host: recommendations # The K8S recommendations service, in addition subset: recommendation-music # to using the labels declared in its Port: # spec.selector attribute, will bind to pods number: 8080 # that also have labels defined in the weight: 100 # recommendation-music subset of the # Destination Rule. ##############################################&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The virtual service uses recommendations that have been filtered to use only pods with labels defined in the &lt;code&gt;recommendation-music&lt;/code&gt; subset of the destination rule.&lt;/p&gt; &lt;p&gt;The virtual service logic that filters the Kubernetes &lt;code&gt;recommendations&lt;/code&gt; service to use only recommendations from the pods in the Kubernetes deployment &lt;code&gt;recommendations-music&lt;/code&gt; is the same as the logic to get the K8S &lt;code&gt;recommendations&lt;/code&gt; service to use only recommendations from the pods in the deployment &lt;code&gt;recommendations-food&lt;/code&gt;. Only in this case the new virtual service filters for music recommendations.&lt;/p&gt; &lt;p&gt;Execute the following command to install the virtual service named &lt;strong&gt;virtual-service-music&lt;/strong&gt; into the OpenShift Service Mesh:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/redhat-developer-demos/simple-service-mesh-demo/main/service-mesh/virtual-service-music.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once the new virtual service is in force, the output from running a POST request against the orders API running within the OpenShift Service Mesh will be similar to the output as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;{ "status": 200, "order": { "payment": { "customer": { "id": 3, "firstName": "Camille", "lastName": "Scott", "email": "Camille.Scott@gmail.com" }, "product": { "id": 2, "category": "Music", "description": "Ernie Ball Guitar Strings", "price": 39.99 }, "creditCard": { "number": "6767-8196-4877-7940-326", "expirationDate": "2023-09-08T01:14:59.686Z", "cvv": "851", "cardHolder": { "id": 3, "firstName": "Camille", "lastName": "Scott", "email": "Camille.Scott@gmail.com" }, "authorizationCode": "93d945c8-af67-43cf-9de0-82f2780ed31f" }, "purchaseDate": 1669844628249, "id": "b132a95b-6238-45dd-b809-995e8a1d5619" }, "recommendation": { "category": "music", "recommendation": "Buy another album by Foo Fighters" }, "id": "fceadf7f-6f04-469d-9922-9a74cfc8d57a" } }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Wrap up&lt;/h2&gt; &lt;p&gt;We have covered a lot of information in this article. I described the nature and use of the OpenShift Service Mesh and  explained details about gateways, virtual service, and destination rules. Then, I demonstrated the steps to get the demo application up and running in an OpenShift Cluster under an OpenShift Service Mesh.&lt;/p&gt; &lt;p&gt;At this point, it would be beneficial to take another look at the diagram in Figure 3 that describes how the various components of an OpenShift Service Mesh work together.&lt;/p&gt; &lt;p&gt;There are four important concepts to remember:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Once an application is bound to an OpenShift Service Mesh by adding the application’s namespace the service mesh’s &lt;code&gt;ServiceMeshMemberRoll&lt;/code&gt; resource, the service mesh is in control of access to and activity within the application.&lt;/li&gt; &lt;li&gt;A gateway enables access to the application within the service mesh.&lt;/li&gt; &lt;li&gt;Virtual services route requests to the application to the underlying Kubernetes services within the OpenShift cluster.&lt;/li&gt; &lt;li&gt;Destination rules define policies and filtering rules that apply to a given virtual service. A subset is a rule within a destination rule.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Service mesh technology is complex. The tradeoff in accommodating this complexity is that using a service mesh makes it easier to control an application at a global level. But, as with any complex technology, working with an OpenShift Service Mesh takes time to master. There are numerous details to juggle. Hopefully, this article has provided the knowledge and hands-on experience required to make it easier to get up and running with OpenShift Service Mesh.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/01/30/run-app-under-openshift-service-mesh" title="4 steps to run an application under OpenShift Service Mesh"&gt;4 steps to run an application under OpenShift Service Mesh&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bob Reselman</dc:creator><dc:date>2023-01-30T07:00:00Z</dc:date></entry><entry><title type="html">Serverless Workflow Validations</title><link rel="alternate" href="https://blog.kie.org/2023/01/serverless-workflow-validations.html" /><author><name>Saravana Balaji</name></author><id>https://blog.kie.org/2023/01/serverless-workflow-validations.html</id><updated>2023-01-27T19:24:27Z</updated><content type="html">Writing a Serverless Workflow that matches with the specification’s rules and schema can require some documentation reading, which demands a few hours. To facilitate that, we have implemented a validation mechanism on our Serverless Workflow Editor, that checks your JSON and YAML files against Serverless Workflow specifications schema and also provides some custom validations in addition to it, that will be detailed below. REQUIREMENTS * (1.66.0+) * (0.26.0) The contains a ready-to-use online version of the Serverless Workflow Editor, where this new feature can be tried by using one of the provided samples or creating a new workflow. SERVERLESS WORKFLOW LANGUAGE SERVICE AND VALIDATION The validation mechanism consists of a dedicated language service for Serverless Workflow, which uses existing JSON and YAML language services as a base and is customized on top of it with the Serverless Workflow specification validation. This feature is provided in both Serverless Logic Web Tools and the built-in editor in the . The validated rules include schema validation and some custom validations, which helps in validating extensive Serverless Workflow nodes like functions, states, events etc. The validation results are highlighted immediately in the editor with a proper message when you hover the error. They can also be seen at the problems section in VS Code or Web Tools. CREATE AND VALIDATE A SERVERLESS WORKFLOW FILE Let’s create a fresh Serverless Workflow from scratch and see how validation works. Create a new file with the ".sw.json” extension. After opening the file in the editor, it will contain an option “Create a Serverless Workflow” at the top. When clicked, it will create a Serverless Workflow specification template, which can also be achieved by using the keyboard shortcut Ctrl + Space. Your workflow can be built on top of this template. You can also check out some interesting Serverless Workflow examples from the repository. SCHEMA VALIDATION The schema validation in Serverless Workflow language service matches the workflow against the schema as per the specification v0.8 released by CNCF. This validation does some strict type checks on every property of the workflow. CUSTOM VALIDATION Serverless Workflow Editor offers some custom validations, which validates the values assigned to Serverless Workflow nodes like functions, states, events etc. This check also includes validating refs like eventRefs, functionRefs, subFlowRefs etc, which comes in handy in assigning the correct references to every property. Let us see how the editor implies custom validations with the example of functions node. VALIDATING FUNCTION NODE First let’s understand the FunctionRef definition a bit. FunctionRef definition can have two types, either string or object. If string, it defines the name of the referenced function from the functions array. "functions": [ { "name": "myFunction", "operation": "localhost#operation", "type": "rest } ], "states": [ { "name": "CheckInbox", "type": "operation", "actionMode": "sequential", "actions": [ { "functionRef": "myFunction" } ], "transition": "SendTextForHighPriority" } ] Similarly, If you need to define parameters in your functionRef definition, you can define it with its object type which has the properties like refName, arguments, selectionSet, invoke. "functions": [ { "name": "checkFundsAvailabe", "operation": "localhost#operation", "type": "rest } ], "state": [ { "refName": "checkFundsAvailabe", "arguments": { "account": { "id": "${ .accountId }" }, "forAmount": "${ .payment.amount }", "insufficientMessage": "The requested amount is not available." } } ] The editor automatically does this extensive validation by the time you enter a value in its properties. It checks if the referenced function name is already part of the functions array and displays a warning if it is not present. VALIDATING OTHER PROMINENT NODES Similar to the functions node, the editor also validates workflow nodes like Auth, Retries, Subflows, Events, States and others. The type checks of these nodes are done by schema validation, while the references passed are validated by the custom validations implemented in addition to it. The detected errors are highlighted immediately in the editor on both Web Tools and the VS Code extension. That is all for now, the extension is already available at the . And stay tuned for our next releases! The post appeared first on .</content><dc:creator>Saravana Balaji</dc:creator></entry><entry><title type="html">First Virtual Technical Exploration for IBM Business Automation Manager Open Edition on February 8 (EMEA time-zone)</title><link rel="alternate" href="https://blog.kie.org/2023/01/first-virtual-technical-exploration-for-ibm-business-automation-manager-open-edition-on-february-8-emea-time-zone.html" /><author><name>Reinhold Engelbrecht</name></author><id>https://blog.kie.org/2023/01/first-virtual-technical-exploration-for-ibm-business-automation-manager-open-edition-on-february-8-emea-time-zone.html</id><updated>2023-01-26T15:54:14Z</updated><content type="html">Karina Varela and myself would like to invite you to this free technical exploration (with hands-on labs) on IBM Business Automation Manager Open Edition (BAM) which is the new name for the former Red Hat PAM/DM products that have recently moved to the IBM Business Automation portfolio. After this session, you will have a good understanding of what this transition means for you. At the same time, you will get familiar with Kogito and design, build and deploy a simple Kogito automation project in OpenShift. The event that is targeted at an European, Middle East and Africa audience. It is also a good chance to get any questions related to the transition answered. You will need to have your computer at hand for accessing the hands-on labs in the IBM Cloud (any operating system, just browser access is needed). As we expect a high interest in this technical exploration and the number of participants is limited due to the hands-on exercises, please fast to secure your seat. AGENDA (STARTING AT 9:30 CET) * IBM Business Automation Manager Open Edition – What the Product Transition Means for You * Overview of cloud-native business automation with Kogito * Hands-on lab: From modelling to testing and deploying a business automation in OpenShift * Demo: Extending the solution with Robotic Process Automation (RPA) * Some other Business Automation capabilities complimenting IBM Business Automation Manager Open Edition * Closing INSTRUCTORS * Fadi Sandakly, Nigel Crowther, Reinhold Engelbrecht – IBM Business Automation Technical Sales EMEA The post appeared first on .</content><dc:creator>Reinhold Engelbrecht</dc:creator></entry><entry><title type="html">This Week in JBoss - 26 January 2023</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2023-01-26.html" /><category term="ansible" /><category term="quarkus" /><category term="java" /><category term="jbang" /><category term="infinispan" /><category term="wildfly" /><category term="cloud-native" /><category term="kia" /><category term="keycloak" /><category term="kafka" /><author><name>Don Naro</name><uri>https://www.jboss.org/people/don-naro</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2023-01-26.html</id><updated>2023-01-26T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="ansible, quarkus, java, jbang, infinispan, wildfly, cloud-native, kia, keycloak, kafka"&gt; &lt;h1&gt;This Week in JBoss - 26 January 2023&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hi everyone! It’s great to be back and bringing you another edition of the JBoss Editorial. As always there’s a lot of exciting news and updates from JBoss communities, so let’s dive in.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-16-0-final-released/"&gt;Quarkus 2.16.0.Final&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-3-0-0-alpha3-released/"&gt;Quarkus 3.0.0.Alpha3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/news/2023/01/18/WildFly2613-Released/"&gt;WildFly 26.1.3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2023/01/keycloak-2003-released"&gt;Keycloak 20.0.3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://infinispan.org/download/"&gt;Infinispan 14.0.6.Final&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_deploying_a_wildfly_cluster_using_ansible"&gt;Deploying a WildFly cluster using Ansible&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/news/2023/01/10/ansible-wildfly/"&gt;Deploying a WildFly 27.0.1 cluster using Ansible&lt;/a&gt;, by Romain Pelisse&lt;/p&gt; &lt;p&gt;Romain treats us to a brief demonstration that uses Ansible to effortlessly set up a WildFly cluster. Romain uses a short, simple playbook that fully automates his deployment and really shows how Ansible collections can greatly simplify configuration and reduce the time it takes to create large clusters with hundreds of nodes.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_listing_maven_local_artifacts_with_jbang"&gt;Listing Maven local artifacts with JBang&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java/how-to-list-maven-local-artifacts-using-jbang/"&gt;How to list Maven local artifacts using JBang&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;I have to say I’m a huge fan of JBang. What’s not to love about an easy-to-use tool that makes scripting with Java a breeze? When I noticed the title of Francesco’s post, I clicked it immediately and dug right in. It did not disappoint and showed a neat JBang CLI script that uses picocli libraries to find the Maven versions of an artifact in your local repository.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_a_look_at_the_apache_kafka_landscape"&gt;A look at the Apache Kafka landscape&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.ofbizian.com/2023/01/apache-kafka-landscape.html"&gt;Apache Kafka Landscape&lt;/a&gt;, by Bilgin Ibryam&lt;/p&gt; &lt;p&gt;Bilgin’s post is a great resource for anyone exploring the Apache Kafka ecosystem and provides a lot of time-saving data around various projects, tools, and services related to Kafka.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quickly_deploying_dashboards_to_github_pages"&gt;Quickly deploying dashboards to GitHub pages&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2023/01/deploying-dashbuilder-dashboards.html"&gt;Deploying Dashbuilder Dashboards&lt;/a&gt;, by William Siqueira&lt;/p&gt; &lt;p&gt;William delivers a snappy article that shows you how to publish Dashbuilder dashboards and easily make them available to users in almost no time at all.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quarkus_native_adopts_adaptive_gc_policy"&gt;Quarkus native adopts adaptive GC policy&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/native-adopts-adaptive-gc-policy/"&gt;Quarkus Native adopts Adaptive GC policy&lt;/a&gt;, by Galder Zamarreño&lt;/p&gt; &lt;p&gt;Galder’s informative post takes us through an examination of the recent change to the garbage collection policy for Quarkus native applications. The change aligns with GraalVM’s default "adaptive" GC policy to provide a better out of the box experience. Galder shows us in spectacular detail how this change brings about more consistent and predictable runtime performance.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_event_driven_ansible_office_hours"&gt;Event-Driven Ansible Office Hours&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://github.com/ansible/event-driven-ansible#office-hours"&gt;Event-driven Ansible Office Hours&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Surely by now you’ve heard of Event-Driven Ansible but maybe you only have a rough idea of how the technology works? Well, great news!&lt;/p&gt; &lt;p&gt;The team have started office hours to demo and explain how Event-Driven Ansible allows you to subscribe to an event-listening source and then quickly and easily automate tasks that respond to those events. Follow the link above to find the latest webinar and learn from the community.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_youtube_videos"&gt;YouTube videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Definitely catch the replay of &lt;a href="https://youtu.be/qcjrGlRimYU"&gt;Quarkus Insights #115: What’s new in Infinispan?&lt;/a&gt; if you haven’t already watched it.&lt;/p&gt; &lt;p&gt;Also check out Sean Cavanaugh’s demo video, &lt;a href="https://youtu.be/aqQq5vD8-n0"&gt;Getting started with Event-Driven Ansible and Ansible Rulebooks&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_see_you_next_time"&gt;See you next time&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;em&gt;Hope you enjoyed this edition. Please join us again in two weeks for our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/don-naro.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Don Naro&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Don Naro</dc:creator></entry></feed>
